
from __future__ import print_function

from keras.models import Sequential
from keras.layers import Dropout, Activation, Convolution2D, GlobalAveragePooling2D, merge
from keras.utils import np_utils
from keras.optimizers import SGD
from keras.models import Model
from keras.layers.core import Lambda
from keras.callbacks import ModelCheckpoint
import pandas
import cPickle
import math



batch_size = 32
nb_classes = 10
nb_epoch = 20

#unpickle is load the cifar 10 data stored in pickled files

def unpickle(file):
    
    with open(file, 'rb') as fo:
        dict = cPickle.load(fo)
    return dict

rows, cols = 32, 32
channels = 3

#datapower 256 contains data which has 256 colours without quantization
x = unpickle('datapower256')
X_train=x['data'][:40000]
print('X_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')
xx=unpickle('datalabels')
Y_train=xx['labels'][:40000]
"""
#test batch
test=unpickle('testbatch')
X_test=test['data']
Y_test=test['labels']
print('X_test shape:', X_test.shape)
print(X_test.shape[0], 'test samples')
"""
#validation batch
valid=unpickle('validation_batch')
X_valid=valid['data']
Y_valid=valid['labels']
print('X_validion shape:', X_valid.shape)
print(X_valid.shape[0], 'validation samples')



Y_train = np_utils.to_categorical(Y_train, nb_classes)

Y_valid = np_utils.to_categorical(Y_valid, nb_classes)


def create_model():
    model = Sequential()
    model.add(Dropout(0.2,input_shape=(32,32,3)))
    model.add(Convolution2D(96, 3, 3, border_mode = 'same'))
    model.add(Activation('relu'))
    model.add(Convolution2D(96, 3, 3,border_mode='same'))
    model.add(Activation('relu'))
    model.add(Convolution2D(96, 3, 3, border_mode='same', subsample = (2,2)))
    model.add(Dropout(0.5))
    model.add(Convolution2D(192, 3, 3, border_mode = 'same'))
    model.add(Activation('relu'))
    model.add(Convolution2D(192, 3, 3,border_mode='same'))
    model.add(Activation('relu'))
    model.add(Convolution2D(192, 3, 3,border_mode='same', subsample = (2,2)))
    model.add(Dropout(0.5))
    model.add(Convolution2D(192, 3, 3, border_mode = 'same'))
    model.add(Activation('relu'))
    model.add(Convolution2D(192, 1, 1,border_mode='valid'))
    model.add(Activation('relu'))
    model.add(Convolution2D(10, 1, 1, border_mode='valid'))
    model.add(GlobalAveragePooling2D())
    model.add(Activation('softmax'))
    return model


X_train = X_train.astype('float32')
#X_test = X_test.astype('float32')
X_valid = X_valid.astype('float32')
X_train /= 255
#X_test /= 255
X_valid/=255


i=8
if(i==2):
    c_model=create_model()
    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
    c_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])
    # Fit the model on the batches generated by datagen.flow().
    j=int(pow(2,i))
    filepath="weights"+str(j)+".hdf5"
    checkpoint=ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=True,save_weights_only=True,mode='max')
    callback=[checkpoint]
    history_callback=c_model.fit(X_train, Y_train,
                                     batch_size=batch_size,
                    
                        nb_epoch=nb_epoch, validation_data=(X_valid, Y_valid), callbacks=callback,verbose=1)
else:
    c_model=create_model()
    m=int(pow(2,i-1))
    c_model.load_weights("weights"+str(m)+".hdf5")
    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
    c_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])
    # Fit the model on the batches generated by datagen.flow().
    j=int(pow(2,i))
    filepath="weights"+str(j)+".hdf5"
    checkpoint=ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=True,save_weights_only=True,mode='max')
    callback=[checkpoint]
    history_callback=c_model.fit(X_train, Y_train,
                                     batch_size=batch_size,
                    
                        nb_epoch=nb_epoch, validation_data=(X_valid, Y_valid), callbacks=callback,verbose=1)






    


